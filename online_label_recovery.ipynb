{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JmRsVJrvJD6-"
   },
   "source": [
    "-------------------------------------------------------------------------------------------------------------------\n",
    "Implementation of : \"Online Label Recovery for Deep Learning-based communication through Error Correcting codes\"\n",
    "\n",
    "Author : Eric Soubigou\n",
    "\n",
    "Date : Spring 2019\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Description :  Creation of a DFE like with Deep Learning technologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "qJ7p4pjiP3ak",
    "outputId": "8a04c1d7-1857-4441-b539-2bac38b68076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/veeresht/CommPy.git@master\n",
      "  Cloning git://github.com/veeresht/CommPy.git (to revision master) to /tmp/pip-req-build-gt688dwr\n",
      "Requirement already satisfied (use --upgrade to upgrade): scikit-commpy==0.3.0 from git+git://github.com/veeresht/CommPy.git@master in /home/eric/.local/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy in /home/eric/.local/lib/python3.6/site-packages (from scikit-commpy==0.3.0) (1.16.2)\n",
      "Requirement already satisfied: scipy in /home/eric/.local/lib/python3.6/site-packages (from scikit-commpy==0.3.0) (1.2.1)\n",
      "Requirement already satisfied: matplotlib in /home/eric/.local/lib/python3.6/site-packages (from scikit-commpy==0.3.0) (3.0.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/eric/.local/lib/python3.6/site-packages (from matplotlib->scikit-commpy==0.3.0) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/eric/.local/lib/python3.6/site-packages (from matplotlib->scikit-commpy==0.3.0) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/eric/.local/lib/python3.6/site-packages (from matplotlib->scikit-commpy==0.3.0) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/eric/.local/lib/python3.6/site-packages (from matplotlib->scikit-commpy==0.3.0) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from cycler>=0.10->matplotlib->scikit-commpy==0.3.0) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->scikit-commpy==0.3.0) (40.8.0)\n",
      "Building wheels for collected packages: scikit-commpy\n",
      "  Building wheel for scikit-commpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-923ei1hu/wheels/d1/6a/31/8ddc70e8eb8a1c3ad344032ed43b4ebfccc41007e8850226d0\n",
      "Successfully built scikit-commpy\n",
      "Requirement already satisfied: torch in /home/eric/.local/lib/python3.6/site-packages (1.0.1.post2)\n",
      "Requirement already satisfied: matplotlib in /home/eric/.local/lib/python3.6/site-packages (3.0.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/eric/.local/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /home/eric/.local/lib/python3.6/site-packages (from matplotlib) (1.16.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/eric/.local/lib/python3.6/site-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/eric/.local/lib/python3.6/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/eric/.local/lib/python3.6/site-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from cycler>=0.10->matplotlib) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (40.8.0)\n",
      "Requirement already satisfied: scipy in /home/eric/.local/lib/python3.6/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /home/eric/.local/lib/python3.6/site-packages (from scipy) (1.16.2)\n",
      "================== DONE ! ==================\n"
     ]
    }
   ],
   "source": [
    "# Install libraries :\n",
    "!pip3 install --user git+git://github.com/veeresht/CommPy.git@master\n",
    "!pip3 install --user torch\n",
    "!pip3 install --user matplotlib\n",
    "!pip3 install --user scipy\n",
    "print(\"================== DONE ! ==================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ka8RHlvyKLf9"
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle # For saving file\n",
    "import copy as cpy\n",
    "\n",
    "# Scipy\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Random\n",
    "import random\n",
    "\n",
    "# Compy\n",
    "from commpy.filters import *\n",
    "import commpy as cp\n",
    "## Simulation import\n",
    "from commpy.channelcoding.convcode import Trellis, conv_encode, viterbi_decode\n",
    "from commpy.modulation import *\n",
    "\n",
    "# For DL libraries \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    FloatTensor = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    FloatTensor = torch.FloatTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LsWpV7tzueky"
   },
   "outputs": [],
   "source": [
    "\"\"\" Return if the number is a power of two. \n",
    ":num: An integer, number to test.\n",
    "\"\"\"\n",
    "def is_power_of_2(num):\n",
    "    return num != 0 and ((num & (num - 1)) == 0)\n",
    "\n",
    "\"\"\" Plot the power density spectrum of a given signal\n",
    ":signal: A 1D-float-array, with the signal samples\n",
    ":time_step: An integer, time step of the signal sampling \n",
    "\"\"\"\n",
    "def plot_spectrum(signal, time_step):\n",
    "    # Go in the frequency domain\n",
    "    spectrum = np.abs(np.fft.fftshift(np.fft.fft(signal))) ** 2\n",
    "    #   f, welch_estimate = sp.signal.welch(signal)\n",
    "    freq = np.fft.fftshift(np.fft.fftfreq(signal.size, d=time_step))\n",
    "    plt.plot(freq, spectrum, \"r\")\n",
    "    #   plt.plot(f, welch_estimate, 'b')\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"OFDM Spectrogram\")\n",
    "    plt.xlabel(\"Frequency [Hz]\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNOjPYRqY_EZ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Emitter class\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Emiter:\n",
    "    \"\"\" Class of the emiter.\n",
    "  \n",
    "  :cp_len: An integer, length of the cyclic-prefix of the OFDM.\n",
    "  :nb_carriers: An integer, number of sub_carrier used to transmit data.\n",
    "  :modulation_order: An integer, the modulation order.\n",
    "  :nb_off_carriers: An integer, number of off carrier in OFDM scheme\n",
    "  :trellis: A compy.channelcoding.Trellis, to encode the data\n",
    "  :pilot_frequency: A integer, number of OFDM symbols/frame before transmitting a pilot\n",
    "  \n",
    "  Ex : | CP | CP | OFF | OFF | ON | ON | ... | ON |\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cp_len,\n",
    "        nb_carriers,\n",
    "        modulation_order,\n",
    "        trellis,\n",
    "        nb_off_carriers=0,\n",
    "        pilot_frequency=8,\n",
    "    ):\n",
    "        self.cp_len = cp_len\n",
    "        self.nb_carriers = nb_carriers\n",
    "        self.nb_off_carriers = nb_off_carriers\n",
    "        # Number of carriers that are used knowing the number of off-carrier\n",
    "        self.nb_on_carriers = self.nb_carriers - self.nb_off_carriers\n",
    "\n",
    "        # For the pilot management\n",
    "        self.pilot_frequency = pilot_frequency\n",
    "\n",
    "        if is_power_of_2(modulation_order):\n",
    "            self.modulator = cp.modulation.PSKModem(modulation_order)\n",
    "        else:\n",
    "            print(\"Wrong modulation order : modulation order = \", modulation_order)\n",
    "\n",
    "        # Generate OFDM pilot symbol\n",
    "        self._pilot_symbols = np.expand_dims(\n",
    "            self.modulator.modulate(\n",
    "                np.zeros(\n",
    "                    self.nb_on_carriers * int(np.log2(modulation_order)), dtype=int\n",
    "                )\n",
    "            ),\n",
    "            axis=1,\n",
    "        ).T\n",
    "\n",
    "        # Test if the trellis is well-defined\n",
    "        if trellis is not None:\n",
    "            self.enc_trellis = trellis\n",
    "        else:\n",
    "            print(\"trellis is not defined\")\n",
    "\n",
    "    def get_trellis(self):\n",
    "        \"\"\" Return the copy of trellis of the emiter\n",
    "        \"\"\"\n",
    "        return cpy.deepcopy(self.enc_trellis)\n",
    "\n",
    "    def modulate_frame(self, frame):\n",
    "        \"\"\" Modulate and Map the frame. In other words, will perform the \n",
    "        Modulation and the Mapping and then perform the OFDM transmormation before \n",
    "        sending the data.\n",
    "        :frame: The frame that has to be modulated.\n",
    "        \"\"\"\n",
    "        # Mapping of the data\n",
    "        mod_frame = self.modulator.modulate(frame)\n",
    "\n",
    "        # Test if the division is equal to an integer or not\n",
    "        if len(mod_frame) % self.nb_on_carriers != 0:\n",
    "            nb_ofdm_group = (len(mod_frame) // self.nb_on_carriers) + 1\n",
    "            # Add padding to the frame in order to get a interger number of PHY\n",
    "            # frames used.\n",
    "\n",
    "            padding = np.zeros(\n",
    "                (self.nb_on_carriers - len(mod_frame) % self.nb_on_carriers)\n",
    "                * self.modulator.num_bits_symbol,\n",
    "                dtype=int,\n",
    "            )\n",
    "            # Add padding to the modulated frame\n",
    "            mod_frame = np.concatenate(\n",
    "                (mod_frame, self.modulator.modulate(padding)), axis=0\n",
    "            )\n",
    "        else:\n",
    "            # No padding to perform\n",
    "            nb_ofdm_group = len(mod_frame) // self.nb_on_carriers\n",
    "\n",
    "        # Then reshape the frame to perform the modulation\n",
    "        carriers = np.reshape(mod_frame, (nb_ofdm_group, self.nb_on_carriers))\n",
    "\n",
    "        # Insert the pilot symbols at the given frequency along rows\n",
    "        carriers = np.insert(\n",
    "            carriers,\n",
    "            np.arange(0, carriers.shape[0], self.pilot_frequency),\n",
    "            self._pilot_symbols,\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "        # Test if there are some off carriers\n",
    "        if self.nb_off_carriers > 0:\n",
    "            # Add the off_carriers\n",
    "            carriers = np.concatenate(\n",
    "                (np.zeros((nb_ofdm_group, self.nb_off_carriers)), carriers), axis=1\n",
    "            )\n",
    "            \n",
    "        # Then use the matrix to transform them into OFDM symbols\n",
    "        ofdm_signal = sp.fftpack.ifft(carriers, axis=1)\n",
    "        #  Add the cyclic prefix\n",
    "        ofdm_signal_cp = np.concatenate(\n",
    "            (ofdm_signal[:, self.nb_carriers - self.cp_len :], ofdm_signal), axis=1\n",
    "        )\n",
    "        # Return the global modulated frame\n",
    "        return np.ravel(ofdm_signal_cp)\n",
    "\n",
    "    def encode(self, frame):\n",
    "        \"\"\" Encode the bit frame according to the defined trellis of the emiter\n",
    "        :frame: The frame that has to be encoded.\n",
    "        \"\"\"\n",
    "        # Channel coding of the frame\n",
    "        return cp.channelcoding.conv_encode(frame, self.enc_trellis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwNk3VH-zJHL"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  AWGN Channel class\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class AWGN_Channel:\n",
    "\n",
    "    \"\"\" Class of the AWGN channel.\n",
    "    :mean: A float, mean of the gaussian noise.\n",
    "    :var: A float, variance of the gaussian noise.\n",
    "    :non_lin_coeff: A float, value of the non-linearity coefficient of the channel.\n",
    "    :iq_imbalance: A float, value of the iq_imbalance.\n",
    "    :channel_taps: A 1-D float-array, containing the value of channel's taps.\n",
    "    :up_factor: A positive integer, value of the upsampling factor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mean,\n",
    "        var,\n",
    "        non_lin_coeff=0,\n",
    "        iq_imbalance=None,\n",
    "        channel_taps=np.ones(1),\n",
    "        up_factor=1,\n",
    "    ):\n",
    "        self.mean = mean\n",
    "        self.var = var\n",
    "        self.gamma = non_lin_coeff\n",
    "        self.beta = iq_imbalance\n",
    "        self.channel_taps = np.divide(channel_taps, np.linalg.norm(channel_taps))\n",
    "        self.up_factor = up_factor\n",
    "\n",
    "    def get_trough(self, mod_frame):\n",
    "        \"\"\" Return the value of the frame after get through the channel\n",
    "        :mod_frame: An array, input of of the channel. Is the modulated frame from an \n",
    "        emiter.\n",
    "        \"\"\"\n",
    "        # Add the IQ imbalance at the emiter side\n",
    "        mod_frame = self.add_iq_imbalance(mod_frame)\n",
    "        # Add the non linearity effect at the emiter side\n",
    "        mod_frame -= self.gamma * (np.abs(mod_frame)) ** 2 * mod_frame\n",
    "        # Go through the multipath channel if the response length is greater than one tap\n",
    "        if len(self.channel_taps) > 1:\n",
    "            # Perform the channel filtering\n",
    "#             print(\"mod_frame before up-sampling\", mod_frame.shape)\n",
    "#             print(\"Mod frame output: \", mod_frame[6:20])\n",
    "            #mod_frame = sp.signal.resample(mod_frame, len(mod_frame)*self.up_factor)\n",
    "#             print(\"mod_frame after up-sampling\", mod_frame.shape)\n",
    "#             print(\"Mod frame output: \", mod_frame[6:20])\n",
    "            # Filter\n",
    "#             print(\"Channel taps\", self.channel_taps)\n",
    "            mod_frame = sp.signal.lfilter(b=self.channel_taps, a=[1], x=mod_frame)\n",
    "#             print(\"mod_frame after filtering\", mod_frame.shape)\n",
    "#             print(\"Mod frame output: \", mod_frame[6:20])\n",
    "            # Down sample the signal\n",
    "            #mod_frame = sp.signal.decimate(mod_frame, q=self.up_factor)\n",
    "#             print(\"mod_frame after decimation\", mod_frame.shape)\n",
    "#             print(\"Mod frame output: \", mod_frame[6:20])\n",
    "#             mod_frame = sp.signal.upfirdn(\n",
    "#                 self.channel_taps, mod_frame, up=self.up_factor, down=self.up_factor\n",
    "#             )\n",
    "            # Then shrink the reponse\n",
    "            #mod_frame = mod_frame[len(self.channel_taps)-1:]\n",
    "        # Add Gaussian noise\n",
    "        output = mod_frame + np.random.normal(self.mean, self.var, mod_frame.shape)\n",
    "        # Add the second IQ imbalance at the receiver side\n",
    "        output = self.add_iq_imbalance(output)\n",
    "        # Add the non linearity effect at the receiver side\n",
    "        output -= self.gamma * np.abs(output) ** 2 * output\n",
    "        return output\n",
    "\n",
    "    def add_iq_imbalance(self, x):\n",
    "        \"\"\" Add IQ imbalance to a given array\n",
    "        :x: An array, input which will be imbalanced accodring to attributes of the \n",
    "        AWGN channel class\n",
    "        \"\"\"\n",
    "        if self.beta is not None:\n",
    "            return self.beta * np.real(x) + 1j * np.imag(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def set_var(self, snr_db, modulation_order):\n",
    "        \"\"\" Set the variance of the gaussian noise of the channel\n",
    "        :snr_db: A float, Value of the Signal to Noise ratio in dB\n",
    "        :modulation_order: An integer, is the moudlation order of the constellation used\n",
    "        \"\"\"\n",
    "        snr = 10 ** (snr_db / 10)\n",
    "        # To define a bit better than it is right now\n",
    "        var_signal = 1\n",
    "        shaped_signal = 1\n",
    "        self.var = (\n",
    "            np.linalg.norm(shaped_signal)\n",
    "            * var_signal\n",
    "            * np.linalg.norm(self.channel_taps)\n",
    "        ) / (2 * np.log2(modulation_order) * snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreEqualizer(nn.Module):\n",
    "    \"\"\" Neural net of the pre-equlizer\n",
    "    :fc_n: fully connected layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symb_nb):\n",
    "        super(Net, self).__init__()\n",
    "        # Set the loss as the MSE loss function. (Not the Cross entropy)\n",
    "        self.loss_function = nn.MSELoss\n",
    "        # Number of symbols accepted in the entry of the neural network\n",
    "        self.symb_nb = symb_nb\n",
    "        #  Fully connected layers\n",
    "        self.fc1 = nn.Linear(2 * self.symb_nb, 256)\n",
    "        self.fc2 = nn.Linear(2 * self.symb_nb, 256)\n",
    "        self.fc3 = nn.Linear(2 * self.symb_nb, 256)\n",
    "        # Init trainable scalar\n",
    "        self.alpha = torch.randn(1, 1)\n",
    "\n",
    "    def forward(self, symbols):\n",
    "        \"\"\" Perform the feedforwar process \n",
    "        :symbols: A 1D float array, containing the symbols to pre-equalize\n",
    "        \"\"\"\n",
    "        # First, adapat the input to the Neural network this means that we\n",
    "        # have to handle the case where there is the CP\n",
    "        pre_equ_symbols = np.array(symbols.shape, dtype=complex)\n",
    "        # Loop on the different chunk of the signal\n",
    "        for i in range(len(symbols) / self.symb_nb):\n",
    "            # Convert the complex array to a 2D real array\n",
    "            formated_symb = from_complex_to_real(\n",
    "                symbols[i * self.symb_nb : (i + 1) * self.symb_nb]\n",
    "            )\n",
    "            # Then feed the neural network with the adapted symbol\n",
    "            out_1 = F.relu(self.fc1(formated_symb))\n",
    "            out_2 = F.relu(self.fc2(out_1))\n",
    "            out_3 = F.linear(self.fc3(out_2))\n",
    "            # Convert the output to a complex vector.\n",
    "            pre_equ_symbols[\n",
    "                i * self.symb_nb : (i + 1) * self.symb_nb\n",
    "            ] = from_real_to_complex(wght_out)\n",
    "        # Lastly we sum the complex input with the ponderated ouptut of the network\n",
    "        return symbols + self.alpha * pre_equ_symbols\n",
    "\n",
    "    def backpropagation(self, output_symb, targeted_symb):\n",
    "        \"\"\" Use to perform the back propagation update\n",
    "        :output_symb:\n",
    "        :targeted_symb:\n",
    "        \"\"\"\n",
    "        loss = self.loss_function(output_symb, targeted_symb)\n",
    "        loss.backward()\n",
    "\n",
    "    def feedback_update(self, x_hat):\n",
    "        \"\"\" Perform a SGD to update the weights given the results of \n",
    "        the viterbi decoder\n",
    "        :x_hat: TODO !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        \"\"\"\n",
    "        x_hat = 1\n",
    "\n",
    "    # Static Methods\n",
    "\n",
    "    @staticmethod\n",
    "    def train(pre_equalizer, received_symb, targeted_symb, nb_epochs, sgd_step=0.01):\n",
    "        \"\"\" To train the NN pre-equalizer.\n",
    "        :pre_equalizer: A Pre_Equalizer, the one which will be trained\n",
    "        :received_symb: A 1D array, received symbols from the OFDM\n",
    "        :targeted_symb: A 1D array of the targeted symbols before the \n",
    "            demaping process\n",
    "        TODO !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        \"\"\"\n",
    "        optimizer = optim.SGD(pre_equalizer.parameters(), lr=sgd_step)\n",
    "        # Loop on the number of epcohs\n",
    "        for epoch in range(nb_epochs):\n",
    "            for i, mini_batch in enumerate(data, 0):\n",
    "                # Zero the gradient buffers\n",
    "                optimizer.zero_grad()\n",
    "                # Perform the forward operation\n",
    "                pre_eq_symbols = pre_equalizer.forward(received_symb)\n",
    "                # Launch the backward function\n",
    "                pre_equalizer.backpropagation(pre_eq_symbols, targeted_symb)\n",
    "                # Perform update of the gradient\n",
    "                optimizer.step()\n",
    "\n",
    "def from_real_to_complex(symbols):\n",
    "    \"\"\" Convert a vector of real 2N symbol into a N complex vetor\n",
    "    with alternate real/imag part of the symbols\n",
    "    :symbols: A 2D-real array, containing the value of symbols.\n",
    "    \"\"\"\n",
    "    # Init of the vector\n",
    "    cmplx = np.array((1, np.round(len(symbols) / 2)), dtype=complex)\n",
    "    cmplx = symbols[0:2:] + j * symbols[1:2:]\n",
    "    return cmplx\n",
    "\n",
    "def from_complex_to_real(symbols):\n",
    "    \"\"\" Convert a vector of complex N symbol into a 2N real vetor\n",
    "    with alternate real/imag part of the symbols\n",
    "    :symbols: A 1D-complex array, containing the value of symbols.\n",
    "    \"\"\"\n",
    "    return np.ravel(np.concatenate((np.real(symbols), np.imag(symbols)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Equalizer class\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Equalizer:\n",
    "    \"\"\" Class of Equalizers\n",
    "    :pilot_symbols: An 1D-float array, beeing the pilots symbol used to estimate \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pilot_symbols):\n",
    "        self.pilot_symbols = pilot_symbols\n",
    "        self.estimation = None\n",
    "        self._name = \"None\"\n",
    "\n",
    "    def equalize(self, symbols_to_equalize):\n",
    "        \"\"\" Equalizes the received frame\n",
    "        :symbols_to_equalize: A 2D-float-array, with the symbol to equalize\n",
    "        \"\"\"\n",
    "        return np.divide(symbols_to_equalize, self.estimation)\n",
    "\n",
    "    def get_name(self):\n",
    "        return self._name\n",
    "\n",
    "\n",
    "class Zero_Forcing(Equalizer):\n",
    "    \"\"\" Zero Forcing equalizers class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pilot_symbols):\n",
    "        super().__init__(pilot_symbols)\n",
    "        self._name = \"Zero-Forcing\"\n",
    "\n",
    "    def estimate(self, received_pilot_symbols):\n",
    "        \"\"\"\n",
    "        :received_pilot_symbols: A 1D-complex-array, containing the signal samples of the \n",
    "            received pilot symbols.\n",
    "        \"\"\"\n",
    "        self.estimation = np.divide(\n",
    "            np.multiply(received_pilot_symbols, np.conjugate(self.pilot_symbols)),\n",
    "            np.power(np.abs(self.pilot_symbols), 2),\n",
    "        )\n",
    "\n",
    "\n",
    "class MMSE(Equalizer):\n",
    "    \"\"\" MMSE equalizers class\n",
    "    :noise_var_est: A float, value of the gaussian noise variance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pilot_symbols):\n",
    "        super().__init__(pilot_symbols)\n",
    "        self._name = \"MMSE\"\n",
    "        self._noise_var_est = 0\n",
    "\n",
    "    def estimate(self, received_pilot_symbols):\n",
    "        \"\"\" Estimate the channel taps following the MMSE principles\n",
    "        :received_pilot_symbols: A 1D-complex-array, containing the signal samples of the \n",
    "            received pilot symbols.\n",
    "        \"\"\"\n",
    "        self.estimation = np.divide(\n",
    "            np.multiply(received_pilot_symbols, np.conjugate(self.pilot_symbols)),\n",
    "            np.linalg.norm(self.pilot_symbols) ** 2 + self._noise_var_est,\n",
    "        )\n",
    "\n",
    "    def set_noise_var(self, noise_var_est):\n",
    "        \"\"\" Set the value of the gaussian noise variance\n",
    "        :noise_var_est: A float, value of the noise variance estimated.\n",
    "        \"\"\"\n",
    "        self._noise_var_est = noise_var_est\n",
    "\n",
    "\n",
    "class NN_Equalizer(Equalizer):\n",
    "    def __init__(self, pilot_symbols):\n",
    "        super().__init__(pilot_symbols)\n",
    "        self._name = \"Zero-Forcing\"\n",
    "\n",
    "        # Instantiate the neural network\n",
    "\n",
    "\n",
    "def switch_init_equalizer(equalizer_name, pilot_symbols):\n",
    "    \"\"\" Instantiate the wanted equalizer given the name of the equalizer\n",
    "    \"\"\"\n",
    "    equalizers = {\n",
    "        \"ZF\": Zero_Forcing(pilot_symbols=pilot_symbols),\n",
    "        \"MMSE\": MMSE(pilot_symbols=pilot_symbols),\n",
    "    }\n",
    "    return equalizers.get(equalizer_name, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Receiver class\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Receiver:\n",
    "\n",
    "    \"\"\" Class of the Receivers\n",
    "    \n",
    "    :cp_len: An integer, length of the cyclic-prefix of the OFDM.\n",
    "    :nb_carriers: An integer, number of sub_carrier used to transmit data.\n",
    "    :modulation_order: An integer, the modulation order.\n",
    "    :nb_off_carriers: An integer, number of off carrier in OFDM scheme\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cp_len,\n",
    "        nb_carriers,\n",
    "        modulation_order,\n",
    "        trellis,\n",
    "        nb_off_carriers=0,\n",
    "        pilot_frequency=8,\n",
    "        equalizer_type=None,\n",
    "    ):\n",
    "        self.cp_len = cp_len\n",
    "        self.nb_carriers = nb_carriers\n",
    "        self.nb_off_carriers = nb_off_carriers\n",
    "        # Number of carriers that are used knowing the number of off-carrier\n",
    "        self.nb_on_carriers = self.nb_carriers - self.nb_off_carriers\n",
    "\n",
    "        # For the pilot management\n",
    "        self.pilot_frequency = pilot_frequency\n",
    "\n",
    "        if is_power_of_2(modulation_order):\n",
    "            self.demodulator = cp.modulation.PSKModem(modulation_order)\n",
    "        else:\n",
    "            print(\"Wrong modulation order : modulation order = \", modulation_order)\n",
    "\n",
    "        # Generate OFDM pilot symbol to use it for future equalization processes\n",
    "        pilot_symbols = np.expand_dims(\n",
    "            self.demodulator.modulate(\n",
    "                np.zeros(\n",
    "                    self.nb_on_carriers * int(np.log2(modulation_order)), dtype=int\n",
    "                )\n",
    "            ),\n",
    "            axis=1,\n",
    "        ).T\n",
    "\n",
    "        # Test if the trellis is well-defined\n",
    "        if trellis is not None:\n",
    "            self.dec_trellis = trellis\n",
    "        else:\n",
    "            print(\"trellis is not defined\")\n",
    "\n",
    "        # Instanciate the Equalizer\n",
    "        if equalizer_type is not None:\n",
    "            # Test which type of equalizer\n",
    "            self.equalizer = switch_init_equalizer(equalizer_type, pilot_symbols)\n",
    "        else:\n",
    "            self.equalizer = None\n",
    "\n",
    "    def demodulate_frame(self, frame, demod_type=\"hard\"):\n",
    "        \"\"\" Demodulate a OFDM received frame\n",
    "        :frame: A 1D array, received frame to demodulate (following OFDM scheme).\n",
    "        :demod_type: 'hard'/'soft', type of demodulation wanted.\n",
    "        \"\"\"\n",
    "        # We reshape the frame at the reception\n",
    "        nb_ofdm_group = len(frame) // (self.cp_len + self.nb_carriers)\n",
    "        received_frame = np.reshape(\n",
    "            frame, (nb_ofdm_group, (self.cp_len + self.nb_carriers))\n",
    "        )\n",
    "        # We delete the cyclic prefix from each frame\n",
    "        received_frame = received_frame[:, self.cp_len :]\n",
    "        # We perform the fft to go from OFDM modulation to standard maping\n",
    "        time_frame = sp.fftpack.fft(received_frame, axis=1)\n",
    "        # Then we delete the part of off-carriers\n",
    "        time_frame = time_frame[:, self.nb_off_carriers :]\n",
    "\n",
    "        # Every two OFDM symbol, we have to extract the pilots symbols of every two frame\n",
    "        # and used it for eqaulization\n",
    "        idx_to_extract = np.arange(0, time_frame.shape[0], self.pilot_frequency + 1)\n",
    "        received_pilot_symbols = time_frame[idx_to_extract, :]\n",
    "        #  And delete the pilot symbols\n",
    "        time_frame = np.delete(time_frame, idx_to_extract, 0)\n",
    "\n",
    "        # Use of an equalizer ?\n",
    "        if self.equalizer is not None:\n",
    "            # Create the new equalized frame which is\n",
    "            eq_time_frame = np.empty((0, time_frame.shape[1]), dtype=complex)\n",
    "            # We iterate over the different pilot symbols\n",
    "            for pilot_idx in range(0, received_pilot_symbols.shape[0]):\n",
    "                # Set the new estimation\n",
    "                self.equalizer.estimate(received_pilot_symbols[pilot_idx, :])\n",
    "                idx = np.arange(\n",
    "                    self.pilot_frequency * pilot_idx,\n",
    "                    np.minimum(\n",
    "                        self.pilot_frequency * (pilot_idx + 1), time_frame.shape[0]\n",
    "                    ),\n",
    "                )\n",
    "                eq_sub_frame = self.equalizer.equalize(time_frame[idx, :])\n",
    "                # Append the equalized results the new equalized frame\n",
    "                eq_time_frame = np.append(eq_time_frame, eq_sub_frame, axis=0)\n",
    "        else:\n",
    "            # No equalization performed\n",
    "            eq_time_frame = time_frame\n",
    "\n",
    "        # Reshape the time frame in a 1D-array\n",
    "        eq_time_frame = np.ravel(eq_time_frame)\n",
    "\n",
    "        # Then we perform the demodulation\n",
    "        return self.demodulator.demodulate(eq_time_frame, demod_type)\n",
    "\n",
    "    def decode(self, enc_frame):\n",
    "        \"\"\" Decoding an encoded frame according to the trellis of the receiver.\n",
    "        :enc_frame: A 1D float array, encoded frame to decode.\n",
    "        \"\"\"\n",
    "        # Decode the received frame according to the trellis\n",
    "        return cp.channelcoding.viterbi_decode(\n",
    "            enc_frame, self.dec_trellis, decoding_type=\"hard\"  # , tb_length=15\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "id": "I3BtmSf-x3RT",
    "outputId": "0f42fa84-41f3-4d53-bade-519b076a0fb5"
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#   Unitary test of Emiter/Receiver class\n",
    "# \"\"\"\n",
    "# # Use of seed\n",
    "# random.seed(2019)\n",
    "# np.random.seed(2019)\n",
    "\n",
    "# # Channel code parameters + trellis generation\n",
    "# mem_size = np.array([2])\n",
    "# g_matrix = np.array([[0o5, 0o7]])\n",
    "# trellis = Trellis(mem_size, g_matrix)\n",
    "\n",
    "# #  Modulation parameters\n",
    "# modulation_order = 8\n",
    "# frame_length = 100\n",
    "\n",
    "# # OFDM parameters (According to the paper \"Online Label Recovery for Deep\n",
    "# # Learning-based communication through Error Correcting codes\")\n",
    "# nb_carriers = 64\n",
    "# cp_length = 8\n",
    "# off_carrier = 0\n",
    "# equalizer = \"ZF\"  # \"ZF\" #\n",
    "\n",
    "# # Creation of the emiter\n",
    "# emiter = Emiter(\n",
    "#     cp_length, nb_carriers, modulation_order, trellis, nb_off_carriers=off_carrier\n",
    "# )\n",
    "\n",
    "# # Basic unitary test\n",
    "# print(\"Modulation exponent: \", emiter.modulator.num_bits_symbol)\n",
    "\n",
    "# # Vizualization of trellis\n",
    "# (emiter.get_trellis()).visualize()\n",
    "\n",
    "# ### Test the frame modulation\n",
    "# # Generation of a frame\n",
    "# frame = np.random.randint(0, high=2, size=(frame_length))\n",
    "# print(\"The frame length is : \", frame.shape)\n",
    "\n",
    "# # Channel Coding by the emiter\n",
    "# enc_frame = emiter.encode(frame)\n",
    "# print(\"The encoded frame length is : \", enc_frame.shape)\n",
    "\n",
    "# # Modulation operation by the emiter\n",
    "# mod_frame = emiter.modulate_frame(enc_frame)\n",
    "# print(\"The modulated frame shape is : \", mod_frame.shape)\n",
    "\n",
    "# # Verification of the spectrum :\n",
    "# plot_spectrum(mod_frame, 1)\n",
    "\n",
    "# # Get through channel\n",
    "# mean = 0\n",
    "# var = 0.3\n",
    "# awgn_channel = AWGN_Channel(\n",
    "#     mean,\n",
    "#     var,\n",
    "#     non_lin_coeff=0,\n",
    "#     iq_imbalance=None,\n",
    "#     channel_taps=np.array([1, 2, 3, 2, 1]),  # np.array([1, 2, 3, 2, 1]),\n",
    "#     up_factor=1,  # nb_carriers + cp_length, TOMODIFY\n",
    "# )\n",
    "\n",
    "# received_frame = awgn_channel.get_trough(mod_frame)\n",
    "\n",
    "# # Creation of the receiver\n",
    "# receiver = Receiver(\n",
    "#     cp_length,\n",
    "#     nb_carriers,\n",
    "#     modulation_order,\n",
    "#     trellis,\n",
    "#     nb_off_carriers=off_carrier,\n",
    "#     equalizer_type=equalizer,\n",
    "# )\n",
    "\n",
    "# # Demodulation of the received frame\n",
    "# demod_frame = receiver.demodulate_frame(received_frame, demod_type=\"hard\")\n",
    "# print(\"The demodulated frame length is : \", demod_frame.shape)\n",
    "\n",
    "# # Shrink for convinience\n",
    "# demod_frame = demod_frame[: len(enc_frame)]\n",
    "# print(\"The demodulated frame length is : \", demod_frame.shape)\n",
    "\n",
    "# # Comparing the error\n",
    "# nb_err_demod = np.sum(demod_frame != enc_frame)\n",
    "# print(\"The number of error after demodulation is :\", nb_err_demod)\n",
    "\n",
    "# # Decoding frame\n",
    "# dec_frame = receiver.decode(demod_frame)\n",
    "# print(\"The decoded frame length is : \", dec_frame.shape)\n",
    "\n",
    "# # Shrink the last part of the decoded frame before comparing the results\n",
    "# dec_frame = dec_frame[: len(frame)]\n",
    "# print(\"The shrink decoded frame length is : \", dec_frame.shape)\n",
    "\n",
    "# # Comparing the error\n",
    "# nb_err = np.sum(dec_frame != frame)\n",
    "# print(\"The number of error is :\", nb_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PHY_Layer:\n",
    "    \"\"\" PHY layer class\n",
    "    :emiter: An Emiter, emiter of the Phy layer\n",
    "    :receiver: An Receiver, receiver of the Phy layer\n",
    "    :channel: A Channel, \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, emiter, receiver, channel):\n",
    "        self.emiter = emiter\n",
    "        self.receiver = receiver\n",
    "        self.channel = channel\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        # Encode the frame\n",
    "        enc_frame = self.emiter.encode(frame)\n",
    "        # Modulate the frame\n",
    "        mod_frame = self.emiter.modulate_frame(enc_frame)\n",
    "        # Go through the channel\n",
    "        channel_frame = self.channel.get_trough(mod_frame)\n",
    "        # Demodulation of the received frame\n",
    "        demod_frame = self.receiver.demodulate_frame(channel_frame, demod_type=\"hard\")\n",
    "        # Shrink for convinience\n",
    "        demod_frame = demod_frame[: len(enc_frame)]\n",
    "        # Decoding frame\n",
    "        dec_frame = self.receiver.decode(demod_frame)\n",
    "        # Shrink the last part of the decoded frame before comparing the results\n",
    "        return dec_frame[: len(frame)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "evetvO6yLlnX"
   },
   "outputs": [],
   "source": [
    "# ### Monte-carlo simulations\n",
    "\n",
    "# # Use of seed\n",
    "# random.seed(2019)\n",
    "# np.random.seed(2019)\n",
    "\n",
    "# # Monte-Carlo parameters\n",
    "# min_error_frame = 100\n",
    "# targeted_fer = 10e-3\n",
    "# max_test = min_error_frame / targeted_fer\n",
    "\n",
    "# # SNR / BER parameters\n",
    "# step_db = 2\n",
    "# min_eb_n0 = 0\n",
    "# max_eb_n0 = 36\n",
    "# eb_n0_db = np.array(range(min_eb_n0, max_eb_n0, step_db))\n",
    "# ber = np.zeros(len(eb_n0_db))\n",
    "# fer = np.zeros(len(eb_n0_db))\n",
    "# ser = np.zeros(len(eb_n0_db))\n",
    "\n",
    "# # Channel parameters\n",
    "# non_lin_coeff = 0\n",
    "# iq_imbalance = None\n",
    "# channel_taps = np.array([1, 2, 3, 2, 1])  # proakis C\n",
    "\n",
    "# # Modulation order of the constellation\n",
    "# modulation_order = 4\n",
    "\n",
    "# # OFDM parameters (According to the paper \"Online Label Recovery for\n",
    "# # Deep Learning-based communication through Error Correcting codes\")\n",
    "# nb_carriers = 64\n",
    "# cp_length = 8\n",
    "# off_carrier = 0\n",
    "\n",
    "# # Type of Equalizer at the receiver side [None, ZF, MMSE]\n",
    "# equalizer = \"MMSE\"  # \"ZF\"\n",
    "\n",
    "# # Emiter / Receiver parameter for trellis\n",
    "# mem_size = np.array([2])\n",
    "# g_matrix = np.array([[0o5, 0o7]])\n",
    "# trellis = Trellis(mem_size, g_matrix)\n",
    "# rho = 1 / 2  #  Coding rate\n",
    "\n",
    "# # Compute the snr_db vector\n",
    "# snr_db = eb_n0_db + 10 * np.log(rho * np.log2(modulation_order))\n",
    "\n",
    "# # Frame length\n",
    "# frame_length = 1000\n",
    "\n",
    "# # Creation of the emiter\n",
    "# emiter = Emiter(\n",
    "#     cp_length, nb_carriers, modulation_order, trellis, nb_off_carriers=off_carrier\n",
    "# )\n",
    "# # Creation of the receiver\n",
    "# receiver = Receiver(\n",
    "#     cp_length,\n",
    "#     nb_carriers,\n",
    "#     modulation_order,\n",
    "#     trellis,\n",
    "#     nb_off_carriers=off_carrier,\n",
    "#     equalizer_type=equalizer,\n",
    "# )\n",
    "\n",
    "# # Creation of the AWGN Channel\n",
    "# awgn_channel = AWGN_Channel(\n",
    "#     mean=0,\n",
    "#     var=0,\n",
    "#     non_lin_coeff=non_lin_coeff,\n",
    "#     iq_imbalance=iq_imbalance,\n",
    "#     channel_taps=channel_taps,\n",
    "# )\n",
    "\n",
    "# # Creation of the PHY Layer\n",
    "# phy_layer = PHY_Layer(emiter, receiver, awgn_channel)\n",
    "\n",
    "# ind_eb_n0 = 0\n",
    "# while (ind_eb_n0 < len(eb_n0_db)) and (\n",
    "#     not (ind_eb_n0 > 0) or (ber[ind_eb_n0 - 1] > 0 and nb_tries < max_test)\n",
    "# ):\n",
    "#     # Init variables\n",
    "#     nb_tries = 0\n",
    "#     nb_frame_error = 0\n",
    "#     global_error_nb = 0\n",
    "#     # Set the snr for the channel\n",
    "#     phy_layer.channel.set_var(eb_n0_db[ind_eb_n0], modulation_order)\n",
    "#     # For the moment, we consider that the noise variance is not estimated\n",
    "#     # but is Genie aided.\n",
    "#     if equalizer == \"MMSE\":\n",
    "#         receiver.equalizer.set_noise_var(phy_layer.channel.var)\n",
    "#     # Monte-Carlo method\n",
    "#     while (nb_tries < max_test) and (nb_frame_error < min_error_frame):\n",
    "#         # Generation of the frames\n",
    "#         frame = np.random.randint(0, high=2, size=frame_length)\n",
    "#         # Send the frame to the physical layer\n",
    "#         recieved_frame = phy_layer.process_frame(frame)\n",
    "#         # Counting errors\n",
    "#         errors_num = np.sum(recieved_frame != frame)\n",
    "#         # Look at the number of mistake\n",
    "#         if errors_num > 0:\n",
    "#             # Add the number of frame errors\n",
    "#             nb_frame_error = nb_frame_error + 1\n",
    "#         global_error_nb = global_error_nb + errors_num\n",
    "#         # increase the number of tries\n",
    "#         nb_tries = nb_tries + 1\n",
    "#     # Update error vectors\n",
    "#     ber[ind_eb_n0] = global_error_nb / (nb_tries * frame_length)\n",
    "#     fer[ind_eb_n0] = nb_frame_error / nb_tries\n",
    "#     #     ser[ind_eb_n0] =\n",
    "#     print(\n",
    "#         \"At \",\n",
    "#         np.floor(100 * ind_eb_n0 / len(eb_n0_db)),\n",
    "#         \" %\",\n",
    "#         \", BER = \",\n",
    "#         ber[ind_eb_n0],\n",
    "#         \", FER = \",\n",
    "#         fer[ind_eb_n0],\n",
    "#         \" for  Eb/N0 = \",\n",
    "#         eb_n0_db[ind_eb_n0],\n",
    "#         \" dB\",\n",
    "#         \", SNR = \",\n",
    "#         snr_db[ind_eb_n0],\n",
    "#         \"dB\",\n",
    "#         \" nb_tries = \",\n",
    "#         nb_tries,\n",
    "#     )\n",
    "#     # Increase the snr index\n",
    "#     ind_eb_n0 += 1\n",
    "\n",
    "# ber_dict = {\n",
    "#     \"trellis\": {\"mem_size\": mem_size, \"g_matrix\": g_matrix},\n",
    "#     \"phy_param\": {\n",
    "#         \"frame_length\": frame_length,\n",
    "#         \"modulation_order\": modulation_order,\n",
    "#         \"rho\": rho,\n",
    "#         \"equalizer\": equalizer,\n",
    "#     },\n",
    "#     \"channel_param\": {\n",
    "#         \"channel_taps\": channel_taps,\n",
    "#         \"non_lin_coeff\": non_lin_coeff,\n",
    "#         \"iq_imbalance\": iq_imbalance,\n",
    "#     },\n",
    "#     \"monte_carlo_param\": {\n",
    "#         \"min_error_frame\": min_error_frame,\n",
    "#         \"targeted_fer\": targeted_fer,\n",
    "#         \"max_test\": max_test,\n",
    "#     },\n",
    "#     \"results\": {\"eb_n0_db\": eb_n0_db, \"snr_db\": snr_db, \"ber\": ber, \"fer\": fer},\n",
    "# }\n",
    "\n",
    "# # Save results in file\n",
    "# filename = \"./results/OFDM_eq_{}_non_lin_coeff_{}_iq_im_{}_snr_{}_to_{}_step_{}.pickle\".format(\n",
    "#     str(equalizer),\n",
    "#     str(non_lin_coeff),\n",
    "#     str(iq_imbalance),\n",
    "#     str(min_eb_n0),\n",
    "#     str(max_eb_n0),\n",
    "#     str(step_db),\n",
    "# )\n",
    "\n",
    "# with open(filename, \"wb\") as handle:\n",
    "#     pickle.dump(ber_dict, handle)\n",
    "\n",
    "# # Display results\n",
    "# plt.plot(eb_n0_db, ber, \"b\")\n",
    "# plt.yscale(\"log\")\n",
    "# plt.title(\"BER restults\")\n",
    "# plt.xlabel(\"Eb/N0 (dB)\")\n",
    "# plt.ylabel(\"BER\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(snr_db, fer, \"b\")\n",
    "# plt.yscale(\"log\")\n",
    "# plt.title(\"FER restults\")\n",
    "# plt.xlabel(\"SNR (dB)\")\n",
    "# plt.ylabel(\"FER\")\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Class for the data set loading.\n",
    "\n",
    "class DatasetSample(Dataset):\n",
    "    \"\"\" Class for the data set of OFDM sample.\n",
    "    Is the implementation of the abstract class Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, transform=None):\n",
    "        \"\"\" Intitialization of the class\n",
    "        \"\"\"\n",
    "        self.samples = pd.rea\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get the sample associated with the index\n",
    "        \"\"\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\" Return the length of the dataset\n",
    "        \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_simulation(sim_param_dict):\n",
    "    \"\"\" Perform the global simulation having the dictionary of parameters.\n",
    "    \n",
    "    :sim_param_dict: A dictionnary containing all parameters necessary for the simualtion\n",
    "    \"\"\"\n",
    "\n",
    "    max_test = (\n",
    "        sim_param_dict[\"m_c_parameters\"][\"min_error_frame\"]\n",
    "        / sim_param_dict[\"m_c_parameters\"][\"targeted_fer\"]\n",
    "    )\n",
    "\n",
    "    #  Simulation parameters\n",
    "    eb_n0_db = np.array(\n",
    "        range(\n",
    "            sim_param_dict[\"m_c_parameters\"][\"min_eb_n0\"],\n",
    "            sim_param_dict[\"m_c_parameters\"][\"max_eb_n0\"],\n",
    "            sim_param_dict[\"m_c_parameters\"][\"step_db\"],\n",
    "        )\n",
    "    )\n",
    "    ber = np.zeros(len(eb_n0_db))\n",
    "    fer = np.zeros(len(eb_n0_db))\n",
    "    ser = np.zeros(len(eb_n0_db))\n",
    "\n",
    "    # Compute the snr_db vector\n",
    "    snr_db = eb_n0_db + 10 * np.log(\n",
    "        sim_param_dict[\"channel_coding\"][\"rho\"]\n",
    "        * np.log2(sim_param_dict[\"modulation\"][\"modulation_order\"])\n",
    "    )\n",
    "\n",
    "    # Creation of the trellis\n",
    "    trellis = Trellis(\n",
    "        sim_param_dict[\"channel_coding\"][\"mem_size\"],\n",
    "        sim_param_dict[\"channel_coding\"][\"g_matrix\"],\n",
    "    )\n",
    "\n",
    "    # Creation of the emiter\n",
    "    emiter = Emiter(\n",
    "        cp_len=sim_param_dict[\"modulation\"][\"cp_length\"],\n",
    "        nb_carriers=sim_param_dict[\"modulation\"][\"nb_carriers\"],\n",
    "        modulation_order=sim_param_dict[\"modulation\"][\"modulation_order\"],\n",
    "        trellis=trellis,\n",
    "        nb_off_carriers=sim_param_dict[\"modulation\"][\"off_carrier\"],\n",
    "    )\n",
    "\n",
    "    # Creation of the receiver\n",
    "    receiver = Receiver(\n",
    "        cp_len=sim_param_dict[\"modulation\"][\"cp_length\"],\n",
    "        nb_carriers=sim_param_dict[\"modulation\"][\"nb_carriers\"],\n",
    "        modulation_order=sim_param_dict[\"modulation\"][\"modulation_order\"],\n",
    "        trellis=trellis,\n",
    "        nb_off_carriers=sim_param_dict[\"modulation\"][\"off_carrier\"],\n",
    "        equalizer_type=sim_param_dict[\"equalizer\"],\n",
    "    )\n",
    "\n",
    "    # Creation of the AWGN Channel\n",
    "    awgn_channel = AWGN_Channel(\n",
    "        mean=0,\n",
    "        var=0,\n",
    "        non_lin_coeff=sim_param_dict[\"channel_parameters\"][\"non_lin_coeff\"],\n",
    "        iq_imbalance=sim_param_dict[\"channel_parameters\"][\"iq_imbalance\"],\n",
    "        channel_taps=sim_param_dict[\"channel_parameters\"][\"channel_taps\"],\n",
    "    )\n",
    "\n",
    "    # File name creation\n",
    "    filename = \"./results/OFDM_eq_{}_non_lin_coeff_{}_iq_im_{}_snr_{}_to_{}_step_{}.pickle\".format(\n",
    "        str(sim_param_dict[\"equalizer\"]),\n",
    "        str(sim_param_dict[\"channel_parameters\"][\"non_lin_coeff\"]),\n",
    "        str(sim_param_dict[\"channel_parameters\"][\"iq_imbalance\"]),\n",
    "        str(sim_param_dict[\"m_c_parameters\"][\"min_eb_n0\"]),\n",
    "        str(sim_param_dict[\"m_c_parameters\"][\"max_eb_n0\"]),\n",
    "        str(sim_param_dict[\"m_c_parameters\"][\"step_db\"]),\n",
    "    )\n",
    "\n",
    "    # Creation of the PHY Layer\n",
    "    phy_layer = PHY_Layer(emiter, receiver, awgn_channel)\n",
    "\n",
    "    nb_tries = 0\n",
    "    ind_eb_n0 = 0\n",
    "\n",
    "    # Launch the simulation\n",
    "    while (ind_eb_n0 < len(eb_n0_db)) and (\n",
    "        not (ind_eb_n0 > 0) or (ber[ind_eb_n0 - 1] > 0 and nb_tries < max_test)\n",
    "    ):\n",
    "        # Init variables\n",
    "        nb_tries = 0\n",
    "        nb_frame_error = 0\n",
    "        global_error_nb = 0\n",
    "        # Set the snr for the channel\n",
    "        phy_layer.channel.set_var(\n",
    "            eb_n0_db[ind_eb_n0], sim_param_dict[\"modulation\"][\"modulation_order\"]\n",
    "        )\n",
    "        # For the moment, we consider that the noise variance is not estimated\n",
    "        # but is Genie aided.\n",
    "        if sim_param_dict[\"equalizer\"] == \"MMSE\":\n",
    "            receiver.equalizer.set_noise_var(phy_layer.channel.var)\n",
    "        # Monte-Carlo method\n",
    "\n",
    "        while (nb_tries < max_test) and (\n",
    "            nb_frame_error < sim_param_dict[\"m_c_parameters\"][\"min_error_frame\"]\n",
    "        ):\n",
    "            # Generation of the frames\n",
    "            frame = np.random.randint(0, high=2, size=sim_param_dict[\"frame_length\"])\n",
    "            # Send the frame to the physical layer\n",
    "            recieved_frame = phy_layer.process_frame(frame)\n",
    "            # Counting errors\n",
    "            errors_num = np.sum(recieved_frame != frame)\n",
    "            # Look at the number of mistake\n",
    "            if errors_num > 0:\n",
    "                # Add the number of frame errors\n",
    "                nb_frame_error = nb_frame_error + 1\n",
    "            global_error_nb = global_error_nb + errors_num\n",
    "            # Increase the number of tries\n",
    "            nb_tries = nb_tries + 1\n",
    "        # Update error vectors\n",
    "        ber[ind_eb_n0] = global_error_nb / (nb_tries * sim_param_dict[\"frame_length\"])\n",
    "        fer[ind_eb_n0] = nb_frame_error / nb_tries\n",
    "        #     ser[ind_eb_n0] =\n",
    "        print(\n",
    "            \"At \",\n",
    "            np.floor(100 * ind_eb_n0 / len(eb_n0_db)),\n",
    "            \" %\",\n",
    "            \", BER = \",\n",
    "            ber[ind_eb_n0],\n",
    "            \", FER = \",\n",
    "            fer[ind_eb_n0],\n",
    "            \" for  Eb/N0 = \",\n",
    "            eb_n0_db[ind_eb_n0],\n",
    "            \" dB\",\n",
    "            \", SNR = \",\n",
    "            snr_db[ind_eb_n0],\n",
    "            \"dB\",\n",
    "            \" nb_tries = \",\n",
    "            nb_tries,\n",
    "        )\n",
    "        # Increase the snr index\n",
    "        ind_eb_n0 += 1\n",
    "        ber_dict = {\n",
    "            \"sim_param\": sim_param_dict,\n",
    "            \"results\": {\"eb_n0_db\": eb_n0_db, \"snr_db\": snr_db, \"ber\": ber, \"fer\": fer},\n",
    "        }\n",
    "        # Save results in file\n",
    "        with open(filename, \"wb\") as handle:\n",
    "            pickle.dump(ber_dict, handle)\n",
    "\n",
    "    # Display results figures\n",
    "    plt.plot(eb_n0_db, ber, \"b\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"BER restults\")\n",
    "    plt.xlabel(\"Eb/N0 (dB)\")\n",
    "    plt.ylabel(\"BER\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(snr_db, fer, \"b\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"FER restults\")\n",
    "    plt.xlabel(\"SNR (dB)\")\n",
    "    plt.ylabel(\"FER\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  0.0  % , BER =  0.45906 , FER =  1.0  for  Eb/N0 =  0  dB , SNR =  0.0 dB  nb_tries =  100\n",
      "At  5.0  % , BER =  0.40772 , FER =  1.0  for  Eb/N0 =  2  dB , SNR =  2.0 dB  nb_tries =  100\n",
      "At  10.0  % , BER =  0.34262 , FER =  1.0  for  Eb/N0 =  4  dB , SNR =  4.0 dB  nb_tries =  100\n",
      "At  15.0  % , BER =  0.29519 , FER =  1.0  for  Eb/N0 =  6  dB , SNR =  6.0 dB  nb_tries =  100\n",
      "At  20.0  % , BER =  0.25512 , FER =  1.0  for  Eb/N0 =  8  dB , SNR =  8.0 dB  nb_tries =  100\n",
      "At  25.0  % , BER =  0.21533 , FER =  1.0  for  Eb/N0 =  10  dB , SNR =  10.0 dB  nb_tries =  100\n",
      "At  30.0  % , BER =  0.16585 , FER =  1.0  for  Eb/N0 =  12  dB , SNR =  12.0 dB  nb_tries =  100\n",
      "At  35.0  % , BER =  0.11207 , FER =  1.0  for  Eb/N0 =  14  dB , SNR =  14.0 dB  nb_tries =  100\n",
      "At  40.0  % , BER =  0.07641 , FER =  1.0  for  Eb/N0 =  16  dB , SNR =  16.0 dB  nb_tries =  100\n",
      "At  45.0  % , BER =  0.05248 , FER =  1.0  for  Eb/N0 =  18  dB , SNR =  18.0 dB  nb_tries =  100\n",
      "At  50.0  % , BER =  0.03602 , FER =  1.0  for  Eb/N0 =  20  dB , SNR =  20.0 dB  nb_tries =  100\n",
      "At  55.0  % , BER =  0.02421 , FER =  1.0  for  Eb/N0 =  22  dB , SNR =  22.0 dB  nb_tries =  100\n",
      "At  60.0  % , BER =  0.01568 , FER =  1.0  for  Eb/N0 =  24  dB , SNR =  24.0 dB  nb_tries =  100\n",
      "At  65.0  % , BER =  0.01002 , FER =  1.0  for  Eb/N0 =  26  dB , SNR =  26.0 dB  nb_tries =  100\n",
      "At  70.0  % , BER =  0.007584158415841584 , FER =  0.9900990099009901  for  Eb/N0 =  28  dB , SNR =  28.0 dB  nb_tries =  101\n",
      "At  75.0  % , BER =  0.004941747572815534 , FER =  0.970873786407767  for  Eb/N0 =  30  dB , SNR =  30.0 dB  nb_tries =  103\n",
      "At  80.0  % , BER =  0.0013859649122807017 , FER =  0.5847953216374269  for  Eb/N0 =  32  dB , SNR =  32.0 dB  nb_tries =  171\n",
      "At  85.0  % , BER =  7.738095238095238e-05 , FER =  0.06613756613756613  for  Eb/N0 =  34  dB , SNR =  34.0 dB  nb_tries =  1512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ac67d4dea6f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m }\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmonte_carlo_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulation_param_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-727df9b53d5b>\u001b[0m in \u001b[0;36mmonte_carlo_simulation\u001b[0;34m(sim_param_dict)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msim_param_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"frame_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# Send the frame to the physical layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mrecieved_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphy_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Counting errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0merrors_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecieved_frame\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-fa45fef71d72>\u001b[0m in \u001b[0;36mprocess_frame\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mdemod_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdemod_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Decoding frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mdec_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemod_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Shrink the last part of the decoded frame before comparing the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdec_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8b2ac303bf12>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, enc_frame)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# Decode the received frame according to the trellis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         return cp.channelcoding.viterbi_decode(\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0menc_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_trellis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoding_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hard\"\u001b[0m  \u001b[0;31m# , tb_length=15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/commpy/channelcoding/convcode.py\u001b[0m in \u001b[0;36mviterbi_decode\u001b[0;34m(coded_bits, trellis, tb_depth, decoding_type)\u001b[0m\n\u001b[1;32m    556\u001b[0m         _acs_traceback(r_codeword, trellis, decoding_type, path_metrics, paths,\n\u001b[1;32m    557\u001b[0m                 \u001b[0mdecoded_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_bits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_depth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 current_number_states)\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mtb_depth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/commpy/channelcoding/convcode.py\u001b[0m in \u001b[0;36m_acs_traceback\u001b[0;34m(r_codeword, trellis, decoding_type, path_metrics, paths, decoded_symbols, decoded_bits, tb_count, t, count, tb_depth, current_number_states)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdecoding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'hard'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0;31m#branch_metric = hamming_dist_c(r_codeword.astype(int), i_codeword_array.astype(int), n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0mbranch_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhamming_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_codeword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_codeword_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mdecoding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'soft'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/commpy/utilities.py\u001b[0m in \u001b[0;36mhamming_dist\u001b[0;34m(in_bitarray_1, in_bitarray_2)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \"\"\"\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_xor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_bitarray_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_bitarray_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0m\u001b[1;32m     35\u001b[0m          initial=_NoValue):\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "simulation_param_dict = {\n",
    "    \"m_c_parameters\": {\n",
    "        \"min_error_frame\": 100,\n",
    "        \"targeted_fer\": 1e-3,\n",
    "        \"step_db\": 2,\n",
    "        \"min_eb_n0\": 0,\n",
    "        \"max_eb_n0\": 40,\n",
    "    },\n",
    "    \"channel_parameters\": {\n",
    "        \"non_lin_coeff\": 0,\n",
    "        \"iq_imbalance\": None,\n",
    "        \"channel_taps\": np.array([1, 2, 3, 2, 1]),\n",
    "    },\n",
    "    \"frame_length\": 256,\n",
    "    \"modulation\": {\n",
    "        \"modulation_order\": 4,\n",
    "        \"nb_carriers\": 64,\n",
    "        \"cp_length\": 8,\n",
    "        \"off_carrier\": 0,\n",
    "    },\n",
    "    \"equalizer\": \"MMSE\",\n",
    "    \"channel_coding\": {\n",
    "        \"mem_size\": np.array([2]),\n",
    "        \"g_matrix\": np.array([[0o5, 0o7]]),\n",
    "        \"rho\": 1 / 2,  #  Coding rate\n",
    "    },\n",
    "}\n",
    "\n",
    "monte_carlo_simulation(simulation_param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_set(dataset_param_dict):\n",
    "    \"\"\" To create a data set and save it.\n",
    "    ::\n",
    "    \"\"\"\n",
    "    # Creation of the trellis\n",
    "    trellis = Trellis(\n",
    "        dataset_param_dict[\"channel_coding\"][\"mem_size\"],\n",
    "        dataset_param_dict[\"channel_coding\"][\"g_matrix\"],\n",
    "    )\n",
    "\n",
    "    # Creation of the emiter\n",
    "    emiter = Emiter(\n",
    "        cp_len=dataset_param_dict[\"modulation\"][\"cp_length\"],\n",
    "        nb_carriers=dataset_param_dict[\"modulation\"][\"nb_carriers\"],\n",
    "        modulation_order=dataset_param_dict[\"modulation\"][\"modulation_order\"],\n",
    "        trellis=trellis,\n",
    "        nb_off_carriers=dataset_param_dict[\"modulation\"][\"off_carrier\"],\n",
    "    )\n",
    "\n",
    "    # Creation of the receiver\n",
    "    receiver = Receiver(\n",
    "        cp_len=dataset_param_dict[\"modulation\"][\"cp_length\"],\n",
    "        nb_carriers=dataset_param_dict[\"modulation\"][\"nb_carriers\"],\n",
    "        modulation_order=dataset_param_dict[\"modulation\"][\"modulation_order\"],\n",
    "        trellis=trellis,\n",
    "        nb_off_carriers=dataset_param_dict[\"modulation\"][\"off_carrier\"],\n",
    "        equalizer_type=dataset_param_dict[\"equalizer\"],\n",
    "    )\n",
    "\n",
    "    # Creation of the AWGN Channel\n",
    "    channel = AWGN_Channel(\n",
    "        mean=0,\n",
    "        var=0,\n",
    "        non_lin_coeff=dataset_param_dict[\"channel_parameters\"][\"non_lin_coeff\"],\n",
    "        iq_imbalance=dataset_param_dict[\"channel_parameters\"][\"iq_imbalance\"],\n",
    "        channel_taps=dataset_param_dict[\"channel_parameters\"][\"channel_taps\"],\n",
    "    )\n",
    "\n",
    "    # Set of the variable\n",
    "    channel.set_var(\n",
    "        dataset_param_dict[\"eb_n0_db\"],\n",
    "        dataset_param_dict[\"modulation\"][\"modulation_order\"],\n",
    "    )\n",
    "\n",
    "    # Generation of the frames\n",
    "    frame = np.random.randint(0, high=2, size=dataset_param_dict[\"frame_length\"])\n",
    "    # Encode the frame\n",
    "    enc_frame = emiter.encode(frame)\n",
    "    # Modulate the frame\n",
    "    mod_frame = emiter.modulate_frame(enc_frame)\n",
    "    # Go through the channel\n",
    "    channel_frame = channel.get_trough(mod_frame)\n",
    "    # Demodulation of the received frame\n",
    "    demod_frame = receiver.demodulate_frame(channel_frame, demod_type=\"hard\")\n",
    "\n",
    "    # Since we get through the channel, we formate the data for a tensor\n",
    "    # We reshape the frame at the reception\n",
    "    nb_ofdm_group = len(mod_frame) // (\n",
    "        dataset_param_dict[\"modulation\"][\"cp_length\"]\n",
    "        + dataset_param_dict[\"modulation\"][\"nb_carriers\"]\n",
    "    )\n",
    "    target_samples = np.reshape(\n",
    "        mod_frame,\n",
    "        (\n",
    "            nb_ofdm_group,\n",
    "            (\n",
    "                dataset_param_dict[\"modulation\"][\"cp_length\"]\n",
    "                + dataset_param_dict[\"modulation\"][\"nb_carriers\"]\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Convert complex values into real and cast into a tensor\n",
    "    target_samples = torch.from_numpy(from_complex_to_real(target_samples))\n",
    "    print(target_samples)\n",
    "    samples = torch.from_numpy(from_complex_to_real(demod_frame))\n",
    "    print(samples)\n",
    "\n",
    "    # Save results in file\n",
    "    filename = \"./data_set/OFDM_non_lin_coeff_{}_iq_im_{}_eb_n0_{}_proakis_C.pt\".format(\n",
    "        str(dataset_param_dict[\"channel_parameters\"][\"non_lin_coeff\"]),\n",
    "        str(dataset_param_dict[\"channel_parameters\"][\"iq_imbalance\"]),\n",
    "        str(dataset_param_dict[\"eb_n0_db\"]),\n",
    "    )\n",
    "\n",
    "    torch.save(target_samples, filename)\n",
    "    \n",
    "    print(\"Data set created at \" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/.local/lib/python3.6/site-packages/commpy/modulation.py:77: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  index_list))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.0404,  0.0214, -0.1156],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b8b2d69a8d8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m }\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mcreate_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set_generation_param_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-e18819d84e22>\u001b[0m in \u001b[0;36mcreate_data_set\u001b[0;34m(dataset_param_dict)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtarget_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_complex_to_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_complex_to_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemod_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-1f137d150dd0>\u001b[0m in \u001b[0;36mfrom_complex_to_real\u001b[0;34m(symbols)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcomplex\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \"\"\"\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "data_set_generation_param_dict = {\n",
    "    \"eb_n0_db\": 10,\n",
    "    \"channel_parameters\": {\n",
    "        \"non_lin_coeff\": 0,\n",
    "        \"iq_imbalance\": None,\n",
    "        \"channel_taps\": np.array([1, 2, 3, 2, 1]),\n",
    "    },\n",
    "    \"frame_length\": 1000,\n",
    "    \"modulation\": {\n",
    "        \"modulation_order\": 4,\n",
    "        \"nb_carriers\": 64,\n",
    "        \"cp_length\": 8,\n",
    "        \"off_carrier\": 0,\n",
    "    },\n",
    "    \"equalizer\": \"MMSE\",\n",
    "    \"channel_coding\": {\n",
    "        \"mem_size\": np.array([2]),\n",
    "        \"g_matrix\": np.array([[0o5, 0o7]]),\n",
    "        \"rho\": 1 / 2,  #  Coding rate\n",
    "    },\n",
    "}\n",
    "\n",
    "create_data_set(data_set_generation_param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "online_label_recovery.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
